{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F-hvs7WrjLy"
      },
      "source": [
        "# Testando o modelo do Detector de Emoções"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz8aXNC5tOyC"
      },
      "source": [
        "## Etapa 1 - Importando as bibliotecas básicas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpYBsKx6raIF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7dd368e5-f8a3-4cc6-b5e4-6b41ea1be950"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow\n",
        "import zipfile\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "tensorflow.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcVgKMKIrGGS"
      },
      "source": [
        "## Etapa 2 - Conexão com o Drive e acesso aos arquivos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3POz78BCrC9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2683987a-a562-46d7-f35f-6c7afef727f4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "path = \"/content/gdrive/My Drive/Material_curso.zip\"\n",
        "zip_object = zipfile.ZipFile(file=path, mode=\"r\")\n",
        "zip_object.extractall(\"./\")\n",
        "zip_object.close"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method ZipFile.close of <zipfile.ZipFile filename='/content/gdrive/My Drive/Material_curso.zip' mode='r'>>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECLyswiCta1B"
      },
      "source": [
        "## Testar com foto capturada da webcam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPiuEyB4twND"
      },
      "source": [
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "VIDEO_HTML = \"\"\"\n",
        "<video autoplay\n",
        " width=%d height=%d style='cursor: pointer;'></video>\n",
        "<script>\n",
        "\n",
        "var video = document.querySelector('video')\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({ video: true })\n",
        "  .then(stream=> video.srcObject = stream)\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "  video.onclick = ()=>{\n",
        "    var canvas = document.createElement('canvas')\n",
        "    var [w,h] = [video.offsetWidth, video.offsetHeight]\n",
        "    canvas.width = w\n",
        "    canvas.height = h\n",
        "    canvas.getContext('2d')\n",
        "          .drawImage(video, 0, 0, w, h)\n",
        "    video.srcObject.getVideoTracks()[0].stop()\n",
        "    video.replaceWith(canvas)\n",
        "    resolve(canvas.toDataURL('image/jpeg', %f))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "def tirar_foto(filename='photo.jpg', quality=2, size=(400,300)):\n",
        "  display(HTML(VIDEO_HTML % (size[0],size[1],quality)))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  f = io.BytesIO(binary)\n",
        "  return np.asarray(Image.open(f))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxLMDPCGuIvk"
      },
      "source": [
        "### Capturando a foto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roHOUgizt-XW"
      },
      "source": [
        "# Clique na imagem da webcam para tirar uma foto\n",
        "imagem = tirar_foto()\n",
        "# Inverte a ordem dos canais (utilizar caso a imagem capturada fique com cores invertidas)\n",
        "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
        "cv2_imshow(imagem)\n",
        "cv2.imwrite(\"testecaptura.jpg\",imagem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKTI2_tArjil"
      },
      "source": [
        "cascade_faces = 'Material_curso/haarcascade_frontalface_default.xml'\n",
        "caminho_modelo = 'Material_curso/modelo_01_expressoes.h5'\n",
        "face_detection = cv2.CascadeClassifier(cascade_faces)\n",
        "classificador_emocoes = load_model(caminho_modelo, compile=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBhzNFgMuNH4"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Carrega o modelo\n",
        "face_detection = cv2.CascadeClassifier(cascade_faces)\n",
        "classificador_emocoes = load_model(caminho_modelo, compile=False)\n",
        "\n",
        "expressoes = [\"Raiva\", \"Nojo\", \"Medo\", \"Feliz\", \"Triste\", \"Surpreso\", \"Neutro\"]\n",
        "\n",
        "original = imagem.copy()\n",
        "faces = face_detection.detectMultiScale(original,scaleFactor=1.1,minNeighbors=3,minSize=(20,20))\n",
        "cinza = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "if len(faces) > 0:\n",
        "    for (fX, fY, fW, fH) in faces:\n",
        "      roi = cinza[fY:fY + fH, fX:fX + fW]\n",
        "      roi = cv2.resize(roi, (48, 48))\n",
        "      roi = roi.astype(\"float\") / 255.0\n",
        "      roi = img_to_array(roi)\n",
        "      roi = np.expand_dims(roi, axis=0)\n",
        "      preds = classificador_emocoes.predict(roi)[0]\n",
        "      print(preds)\n",
        "      emotion_probability = np.max(preds)\n",
        "      label = expressoes[preds.argmax()]\n",
        "      cv2.putText(original, label, (fX, fY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "      cv2.rectangle(original, (fX, fY), (fX + fW, fY + fH),(0, 0, 255), 2)\n",
        "else:\n",
        "    print('Nenhuma face detectada')\n",
        "\n",
        "\n",
        "cv2_imshow(original)\n",
        "\n",
        "probabilidades = np.ones((250, 300, 3), dtype=\"uint8\") * 255\n",
        "# Mostra gráfico apenas se detectou uma face\n",
        "if len(faces) == 1:\n",
        "  for (i, (emotion, prob)) in enumerate(zip(expressoes, preds)):\n",
        "      # Nome das emoções\n",
        "      text = \"{}: {:.2f}%\".format(emotion, prob * 100)\n",
        "      w = int(prob * 300)\n",
        "      cv2.rectangle(probabilidades, (7, (i * 35) + 5),\n",
        "      (w, (i * 35) + 35), (200, 250, 20), -1)\n",
        "      cv2.putText(probabilidades, text, (10, (i * 35) + 23),\n",
        "      cv2.FONT_HERSHEY_SIMPLEX, 0.45,\n",
        "      (0, 0, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "  cv2_imshow(probabilidades)\n",
        "\n",
        "cv2.imwrite(\"captura.jpg\",original)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}