{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Testando o modelo do detector de emoções"
      ],
      "metadata": {
        "id": "JWj617a5sNVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Etapa 1 - Importando as bibliotecas**"
      ],
      "metadata": {
        "id": "kd1hEfamsZo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "dnAqgYrFsRyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YZCVbDQrZ9l",
        "outputId": "92f4d9b8-ef8a-40a3-bf72-f221de7771b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "tensorflow.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B2E3-Apfsovn",
        "outputId": "a889ea5a-d0a4-49bf-a189-0ed7d4b234a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Etapa 2 - Conectando com o Drive e acessando os arquivos**"
      ],
      "metadata": {
        "id": "HpQGmUwSsr1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMyp9QZOss5d",
        "outputId": "814f60ea-c897-41c4-fbb1-b7ea15715fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/gdrive/MyDrive/Material_curso.zip\"\n",
        "zip_object = zipfile.ZipFile(file = path, mode = \"r\")\n",
        "zip_object.extractall('./')\n",
        "zip_object.close"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTKbfLATs14p",
        "outputId": "901c4cba-e21c-490f-f459-0c8ba3000df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method ZipFile.close of <zipfile.ZipFile filename='/content/gdrive/MyDrive/Material_curso.zip' mode='r'>>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imagem = cv2.imread('/content/Material_curso/testes/mulher_feliz.jpg')\n",
        "cv2_imshow(imagem)"
      ],
      "metadata": {
        "id": "0FUKVXqps4c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem.shape"
      ],
      "metadata": {
        "id": "58R0P8pDs9i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testando o Detector"
      ],
      "metadata": {
        "id": "F1dcOL2Us-c6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Carregamento dos modelos**"
      ],
      "metadata": {
        "id": "oBSYHvshtG1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cascade_faces = \"Material_curso/haarcascade_frontalface_default.xml\"\n",
        "caminho_modelo = \"Material_curso/modelo_01_expressoes.h5\"\n",
        "face_detection = cv2.CascadeClassifier(cascade_faces)\n",
        "classificador_emocoes = load_model(caminho_modelo, compile = False)\n",
        "expressoes = [\"Raiva\", \"Nojo\", \"Medo\", \"Feliz\", \"Triste\", \"Surpreso\", \"Neutro\"]"
      ],
      "metadata": {
        "id": "3iSl7g35tLyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Detecção de faces**"
      ],
      "metadata": {
        "id": "lZjvm6-xtSiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original = imagem.copy()\n",
        "faces = face_detection.detectMultiScale(original, scaleFactor = 1.1,\n",
        "                                        minNeighbors = 3, minSize = (20,20))"
      ],
      "metadata": {
        "id": "LHxinBQltP7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faces"
      ],
      "metadata": {
        "id": "hDzrtyMbtWSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(faces)"
      ],
      "metadata": {
        "id": "MZwMXRaVtY_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faces.shape"
      ],
      "metadata": {
        "id": "xKg8lO11ta3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extração do ROI (região de interesse)**"
      ],
      "metadata": {
        "id": "wUOyqNYEtdEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cinza = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
        "cv2_imshow(cinza)"
      ],
      "metadata": {
        "id": "RCDj1VR7ti4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cinza.shape"
      ],
      "metadata": {
        "id": "XlMR3r-wt7Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roi = cinza[68:68 + 200, 446:446 + 200]"
      ],
      "metadata": {
        "id": "xgsXAb_2t71p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(roi)"
      ],
      "metadata": {
        "id": "RZONqMOut-lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roi.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CchQvOdCuC8e",
        "outputId": "05924409-02b6-417b-e09d-563d488d2831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roi"
      ],
      "metadata": {
        "id": "quZCIvRSuDUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roi = cv2.resize(roi, (48, 48))\n",
        "cv2_imshow(roi)"
      ],
      "metadata": {
        "id": "GHXSVAsOuGRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roi.dtype"
      ],
      "metadata": {
        "id": "B_3W7xC0uHFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roi = roi.astype('float')\n",
        "roi.dtype"
      ],
      "metadata": {
        "id": "goXsG6PkuJtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roi"
      ],
      "metadata": {
        "id": "DiaKbWz9uMkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roi = roi / 255"
      ],
      "metadata": {
        "id": "J5xPXCLpuOs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roi"
      ],
      "metadata": {
        "id": "C-Kzu9SXuQvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roi = img_to_array(roi)"
      ],
      "metadata": {
        "id": "M7cuaCXTuSm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roi"
      ],
      "metadata": {
        "id": "n1ExgePbuU1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roi.shape"
      ],
      "metadata": {
        "id": "iWwBUD2ZuZVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roi = np.expand_dims(roi, axis = 0)"
      ],
      "metadata": {
        "id": "Qq5YcHSpuc5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roi.shape"
      ],
      "metadata": {
        "id": "5Q7OXylBue-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Previsões"
      ],
      "metadata": {
        "id": "YzNCm0mDufon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = classificador_emocoes.predict(roi)[0]"
      ],
      "metadata": {
        "id": "mD3XuJyTum5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "id": "AmOtc5x0upWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(preds)"
      ],
      "metadata": {
        "id": "cMFPPz4iurKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_probability = np.max(preds)\n",
        "emotion_probability"
      ],
      "metadata": {
        "id": "8mIq2KyEutVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds.argmax()"
      ],
      "metadata": {
        "id": "wXyqIN_KuvkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = expressoes[preds.argmax()]\n",
        "label"
      ],
      "metadata": {
        "id": "BrJcA-v_uy4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resultados"
      ],
      "metadata": {
        "id": "NXoPm1rwu0zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.putText(original, label, (446, 68 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.65,\n",
        "            (0, 0, 255), 2, cv2.LINE_AA)\n",
        "cv2.rectangle(original, (446, 68), (446 + 200, 68 + 200), (0, 0, 255), 2)\n",
        "cv2_imshow(original)"
      ],
      "metadata": {
        "id": "n_wY4pA8xi-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilidades = np.ones((250,300,3), dtype= 'uint8') * 255 #inteiro\n",
        "probabilidades"
      ],
      "metadata": {
        "id": "NfffMI9DhXmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilidades.shape"
      ],
      "metadata": {
        "id": "017vpO7ShXcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(original)\n",
        "if len(faces) == 1:\n",
        "  for (i, (emotion, prob)) in enumerate(zip(expressoes, preds)):\n",
        "    #print(i, emotion, prob)\n",
        "    text = \"{}: {:.2f}%\".format(emotion, prob * 100)\n",
        "    w = int(prob * 300)\n",
        "    cv2.rectangle(probabilidades, (7, (i * 35) + 5), (w, (i * 35) + 35), (200, 250, 20), -1)\n",
        "    cv2.putText(probabilidades, text, (10, (i * 35) + 23), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 0), 1, cv2.LINE_AA)\n",
        "cv2_imshow(probabilidades)"
      ],
      "metadata": {
        "id": "fZsPO1Ibib6T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}