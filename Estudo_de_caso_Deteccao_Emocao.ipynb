{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWPgmYF0YWuc"
      },
      "source": [
        "## Etapa 1 - Importando as bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTjPR159Rxid"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import zipfile\n",
        "\n",
        "cv2.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMHGoSG-7run"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbhivnG9Y8Zb"
      },
      "source": [
        "## Etapa 2 - Conectando com o Drive e acessando os arquivos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB_J0KIRZEdW"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuU-LKcu8Qun"
      },
      "source": [
        "path = \"/content/gdrive/My Drive/Material.zip\"\n",
        "zip_object = zipfile.ZipFile(file=path, mode=\"r\")\n",
        "zip_object.extractall(\"./\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18KiFVig6xaS"
      },
      "source": [
        "base_imgs = 'Material/fer2013.zip'\n",
        "zip_object = zipfile.ZipFile(file = base_imgs, mode = 'r')\n",
        "zip_object.extractall('./')\n",
        "zip_object.close"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOISQ9jRaeQ0"
      },
      "source": [
        "## Etapa 3 - Acessando a base com fotos de expressões faciais\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I4NJOuX-gl5"
      },
      "source": [
        "data = pd.read_csv('fer2013/fer2013.csv')\n",
        "data.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQpVm9Fl-zOl"
      },
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.hist(data['emotion'], bins = 30)\n",
        "plt.title('Imagens x emoções')\n",
        "\n",
        "# Classes: ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsUmk_-HbXJo"
      },
      "source": [
        "## Etapa 4 - Pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4PS0yuPAXqN"
      },
      "source": [
        "pixels = data['pixels'].tolist()\n",
        "pixels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Jh0WwAAraH"
      },
      "source": [
        "largura, altura = 48, 48\n",
        "faces = []\n",
        "amostras = 0\n",
        "for pixel_sequence in pixels:\n",
        "  face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "  face = np.asarray(face).reshape(largura, altura)\n",
        "  faces.append(face)\n",
        "\n",
        "  if (amostras < 10):\n",
        "    cv2_imshow(face)\n",
        "  amostras += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQsmRXvVCRG5"
      },
      "source": [
        "print('Número total de imagens no dataset: ', str(len(faces)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkMJn2rBCdmv"
      },
      "source": [
        "faces = np.asarray(faces)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXmUtnPfCqe_"
      },
      "source": [
        "faces.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1SbyrlACukv"
      },
      "source": [
        "faces = np.expand_dims(faces, -1)\n",
        "faces.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnHeDiUkC-3z"
      },
      "source": [
        "def normalizar(x):\n",
        "  x = x.astype('float32')\n",
        "  x = x / 255.0\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku9T5xXeDTT_"
      },
      "source": [
        "faces = normalizar(faces)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIwt0h1PDWvH"
      },
      "source": [
        "faces[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Pd1HGKSDc0p"
      },
      "source": [
        "emocoes = pd.get_dummies(data['emotion']).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70zeJfafDn1g"
      },
      "source": [
        "emocoes[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEeGAoXUb1z1"
      },
      "source": [
        "## Etapa 5 - Imports do Tensorflow/Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tm00l7YEdK2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import model_from_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNQB1Vkxm10R"
      },
      "source": [
        "## Etapa 6 - Dividir em conjuntos para treinamento e validação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT5_JlaPGXpq"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(faces, emocoes, test_size = 0.1, random_state = 42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 41)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGF4L844HJgE"
      },
      "source": [
        "print('Número de imagens no conjunto de treinamento:', len(X_train))\n",
        "print('Número de imagens no conjunto de teste:', len(X_test))\n",
        "print('Número de imagens no conjunto de validação:', len(X_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8MuZUFSq3sN"
      },
      "source": [
        "np.save('mod_xtest', X_test) #base de dados para a matriz de confusão\n",
        "np.save('mod_ytest', y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0niLQhS8cCXM"
      },
      "source": [
        "## Etapa 7 - Arquitetura do Modelo (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0uyRxZCcM56"
      },
      "source": [
        "### Arquitetura 1 do modelo\n",
        "\n",
        "Padding same x valid: https://www.corvil.com/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow\n",
        "\n",
        "Implementação original: https://medium.com/@birdortyedi_23820/deep-learning-lab-episode-3-fer2013-c38f2e052280\n",
        "\n",
        "Regularizers: https://keras.io/regularizers/\n",
        "\n",
        "Dropout: http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtaJ0EpnJ0vg"
      },
      "source": [
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "width, height = 48, 48\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(num_features, kernel_size=(3,3), activation='relu',\n",
        "                 input_shape=(width, height, 1), data_format = 'channels_last',\n",
        "                 kernel_regularizer = l2(0.01)))\n",
        "model.add(Conv2D(num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(2*2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(2*2*2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*2*2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(2*2*2*num_features, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(2*2*num_features, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(2*num_features, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_labels, activation = 'softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4wjf2RydVfI"
      },
      "source": [
        "## Etapa 8 - Compilando o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJcdjk6NdlU9"
      },
      "source": [
        "Parâmetros Adam: https://arxiv.org/abs/1412.6980\n",
        "\n",
        "Artigo Adam: https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
        "\n",
        "beta: Taxa de decaimento exponencial (por exemplo, 0.9)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV9FXeskVgIz"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', #classificação - calculo dos erros\n",
        "              optimizer = Adam(lr = 0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7), #atualização dos pesos / taxa decaimento tx aprendizagem\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "arquivo_modelo = 'modelo_01_expressoes.h5' # modelos salvos - cj dos pesos de aprendizado da rede neural\n",
        "arquivo_modelo_json = 'modelo_01_expressoes.json' #estrutura da rede neural\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor = 0.9, patience=3, verbose = 1)\n",
        "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience = 8, verbose = 1, mode = 'auto')\n",
        "checkpointer = ModelCheckpoint(arquivo_modelo, monitor='val_loss', verbose = 1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjDXOgXeKiNw"
      },
      "source": [
        "### Salvando a arquitetura do modelo em um arquivo JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGDxx9HMY4vR"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(arquivo_modelo_json, 'w') as json_file:\n",
        "  json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLOT-lBmd2OS"
      },
      "source": [
        "## Etapa 9 - Treinando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2aq0b41Zy3U"
      },
      "source": [
        "history = model.fit(np.array(X_train), np.array(y_train),\n",
        "                    batch_size = batch_size, #64\n",
        "                    epochs = epochs, #100\n",
        "                    verbose = 1,\n",
        "                    validation_data = (np.array(X_val), np.array(y_val)),\n",
        "                    shuffle=True,\n",
        "                    callbacks=[lr_reducer, early_stopper, checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPb7IuHGo-eJ"
      },
      "source": [
        "print(history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqqVAsrTdygt"
      },
      "source": [
        "## Gerando gráfico da melhora em cada etapa do treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_nbMxbrmF2e"
      },
      "source": [
        "def plota_historico_modelo(historico_modelo):\n",
        "  fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
        "  axs[0].plot(range(1, len(historico_modelo.history['accuracy']) + 1), historico_modelo.history['accuracy'], 'r')\n",
        "  axs[0].plot(range(1, len(historico_modelo.history['val_accuracy']) + 1), historico_modelo.history['val_accuracy'], 'b')\n",
        "  axs[0].set_title('Acurácia do modelo')\n",
        "  axs[0].set_ylabel('Acurácia')\n",
        "  axs[0].set_xlabel('Epoch')\n",
        "  #axs[0].set_xticks(np.arange(1, len(historico_modelo.history['accuracy']) + 1),\n",
        "                    #len(historico_modelo.history['accuracy']) / 10)\n",
        "  axs[0].legend(['training accuracy', 'validation accuracy'], loc = 'best')\n",
        "\n",
        "  axs[1].plot(range(1, len(historico_modelo.history['loss']) + 1), historico_modelo.history['loss'], 'r')\n",
        "  axs[1].plot(range(1, len(historico_modelo.history['val_loss']) + 1), historico_modelo.history['val_loss'], 'b')\n",
        "  axs[1].set_title('Loss do modelo')\n",
        "  axs[1].set_ylabel('Loss')\n",
        "  axs[1].set_xlabel('Epoch')\n",
        "  #axs[1].set_xticks(np.arange(1, len(historico_modelo.history['loss']) + 1),\n",
        "                    #len(historico_modelo.history['loss']) / 10)\n",
        "  axs[1].legend(['training loss', 'validation loss'], loc = 'best')\n",
        "  fig.savefig('historico_modelo_mod01.png')\n",
        "\n",
        "plota_historico_modelo(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOVHCZvEGZb4"
      },
      "source": [
        "### Verificando a acurácia do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV4PFh8cp0Se"
      },
      "source": [
        "scores = model.evaluate(np.array(X_test), np.array(y_test), batch_size = batch_size) #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmyNzcF6qDvn"
      },
      "source": [
        "scores # erro x acurárcia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQNOl_hgqKFE"
      },
      "source": [
        "print('Acurácia: ' + str(scores[1]))\n",
        "print('Erro: ' + str(scores[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHh7NxjOZ2bD"
      },
      "source": [
        "## Carregamento dos dados para gerar a matriz de confusão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bpg3JXxrToo"
      },
      "source": [
        "true_y = [] #valores reais e das predições\n",
        "pred_y = []\n",
        "x = np.load('mod_xtest.npy')\n",
        "y = np.load('mod_ytest.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnCH_x39rhhd"
      },
      "source": [
        "x[0] #valores dos pixels da primeira imagem"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcTNmGvfrk4S"
      },
      "source": [
        "y[0] #valor da emoção"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdulaCzfrv1j"
      },
      "source": [
        "json_file = open(arquivo_modelo_json, 'r') #carregar o modelo salvo com a estrutura da rede neural\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-7ZCLolsAbk"
      },
      "source": [
        "loaded_model = model_from_json(loaded_model_json) #transformar o modelo h5\n",
        "loaded_model.load_weights(arquivo_modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYtwZS-4tKlJ"
      },
      "source": [
        "y_pred = loaded_model.predict(x) #predição dos pixels de cada uma das imagens de cada uma das emoções"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ftjf8zqBtVJt"
      },
      "source": [
        "y_pred[0] #verificar a qual classe cada uma das predições corresponde"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9Hng3z5ta76"
      },
      "source": [
        "yp = y_pred.tolist() #transformar em uma lista\n",
        "yt = y.tolist() #com respostas reais\n",
        "count = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGlq_RkltzDz"
      },
      "source": [
        "len(y) #quantidade de registros na base de dados de teste"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4GmOX5stvgP"
      },
      "source": [
        "for i in range(len(y)):\n",
        "  yy = max(yp[i]) #maior valor da probabilidade\n",
        "  yyt = max(yt[i])\n",
        "  pred_y.append(yp[i].index(yy))\n",
        "  true_y.append(yt[i].index(yyt))\n",
        "  if (yp[i].index(yy) == yt[i].index(yyt)):\n",
        "    count += 1\n",
        "\n",
        "acc = (count / len(y)) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z-SFPHZvpBI"
      },
      "source": [
        "print('Acurácia no conjunto de teste: ' + str(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH3C27ydv6Wn"
      },
      "source": [
        "np.save('truey_mod01', true_y)\n",
        "np.save('predy_mod01', pred_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tjZ91OoZ99v"
      },
      "source": [
        "## Gerando a Matriz de Confusão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8xaMEZIwoqS"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySRui5L1wxOD"
      },
      "source": [
        "y_true = np.load('truey_mod01.npy')\n",
        "y_pred = np.load('predy_mod01.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a9n1z9Ew9IM"
      },
      "source": [
        "cm = confusion_matrix(y_true, y_pred) #matriz de acertos classe por classe\n",
        "expressoes = ['Raiva', 'Nojo', 'Medo', 'Feliz', 'Triste', 'Surpreso', 'Neutro']\n",
        "titulo = 'Matriz de Confusão'\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWYqHqv3yVGT"
      },
      "source": [
        "import itertools\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title(titulo)\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(expressoes))\n",
        "plt.xticks(tick_marks, expressoes, rotation = 45)\n",
        "plt.yticks(tick_marks, expressoes)\n",
        "fmt = 'd'\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "  plt.text(j, i, format(cm[i, j], fmt), horizontalalignment='center', color='white' if cm[i,j] > thresh else 'black')\n",
        "\n",
        "plt.ylabel('Classificação correta')\n",
        "plt.xlabel('Predição')\n",
        "plt.savefig('matriz_confusao_mod01.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfC8RYZmpBFk"
      },
      "source": [
        "## Testando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuFXmdqK1in2"
      },
      "source": [
        "imagem = cv2.imread('Material/testes/teste02.jpg')\n",
        "cv2_imshow(imagem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PVbxF-p17b3"
      },
      "source": [
        "original = imagem.copy()\n",
        "gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta4mlXSd2RUr"
      },
      "source": [
        "face_cascade = cv2.CascadeClassifier('Material/haarcascade_frontalface_default.xml')\n",
        "faces = face_cascade.detectMultiScale(gray, 1.1, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plahe7N52pWd"
      },
      "source": [
        "faces #8 posições para cada face"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRIrkxGQ2u_w"
      },
      "source": [
        "for (x, y, w, h) in faces:\n",
        "  cv2.rectangle(original, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
        "  roi_gray = gray[y:y + h, x:x + w]\n",
        "  roi_gray = roi_gray.astype('float') / 255.0\n",
        "  cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
        "  prediction = loaded_model.predict(cropped_img)[0]\n",
        "  cv2.putText(original, expressoes[int(np.argmax(prediction))], (x, y - 10),\n",
        "              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "cv2_imshow(original)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}